max_depth=4,
min_child_weight=1,
subsample=1,
colsample_bytree=1)
#run the boost algo with those settings
xgb_naive_fd_bm5 <- xgb.train(params = params,
data = dtrain_fd_bm5,
nrounds = 500,
watchlist = list(train = dtrain_fd_bm5,
val = dtest_fd_bm5),
print_every_n = 25,
early_stopping_rounds = 10,
maximize = F)
#set the parameters of the boost algo
params <- list(booster = "gbtree",
objective = "reg:squarederror",
eta=0.05,
gamma=0,
max_depth=3,
min_child_weight=1,
subsample=1,
colsample_bytree=1)
#run the boost algo with those settings
xgb_naive_fd_bm5 <- xgb.train(params = params,
data = dtrain_fd_bm5,
nrounds = 500,
watchlist = list(train = dtrain_fd_bm5,
val = dtest_fd_bm5),
print_every_n = 25,
early_stopping_rounds = 10,
maximize = F)
#set the parameters of the boost algo
params <- list(booster = "gbtree",
objective = "reg:squarederror",
eta=0.05,
gamma=0,
max_depth=3,
min_child_weight=1,
subsample=1,
colsample_bytree=1)
#run the boost algo with those settings
xgb_naive_fd_bm5 <- xgb.train(params = params,
data = dtrain_fd_bm5,
nrounds = 500,
watchlist = list(train = dtrain_fd_bm5,
val = dtest_fd_bm5),
print_every_n = 25,
early_stopping_rounds = 10,
maximize = F)
preds_fd_bm5 <- test_fiveDay %>% mutate(predicted_fd_bm5 = predict(xgb_naive_fd_bm5, dtest_fd_bm5))
evals_fd_bm5 <- preds_fd_bm5 %>%
summarise(rmse = rmse(secchi, predicted_fd_bm5),
mae = mae(secchi, predicted_fd_bm5),
mape = mape(secchi, predicted_fd_bm5),
bias = bias(secchi, predicted_fd_bm5),
p.bias = percent_bias(secchi, predicted_fd_bm5),
smape = smape(secchi, predicted_fd_bm5))
ggplot(preds_fd_bm5, aes(x = secchi, y = predicted_fd_bm5)) +
geom_point() +
geom_abline(color = 'grey', lty = 2) +
coord_cartesian(xlim = c(0, 6.5),
ylim = c(0,6.5)) +
stat_poly_eq(aes(label = paste(after_stat(adj.rr.label))),
formula = y~x,
parse = TRUE,
label.y = Inf,
vjust = 1.3) +
labs(title = 'Quick xgboost - Yojoa Secchi\nfive day matchups, band and 5-day met summaries',
subtitle = 'Grey dashed line is 1:1',
x = 'Actual Secchi (m)',
y = 'Predicted Secchi (m)')  +
theme_bw()+
theme(plot.title = element_text(hjust = 0.5, face = 'bold'),
plot.subtitle = element_text(hjust = 0.5))
#set the parameters of the boost algo
params <- list(booster = "gbtree",
objective = "reg:squarederror",
eta=0.5,
gamma=1,
max_depth=5,
min_child_weight=2,
subsample=1,
colsample_bytree=1)
#run the boost algo with those settings
xgb_naive_fd_bm5_play <- xgb.train(params = params,
data = dtrain_fd_bm5,
nrounds = 1000,
watchlist = list(train = dtrain_fd_bm5,
val = dtest_fd_bm5),
print_every_n = 25,
early_stopping_rounds = 10,
maximize = F)
preds_fd_bm5_play <- test_fiveDay %>% mutate(predicted_fd_bm5 = predict(xgb_naive_fd_bm5_play, dtest_fd_bm5))
evals_fd_bm5_play <- preds_fd_bm5_play %>%
summarise(rmse = rmse(secchi, predicted_fd_bm5),
mae = mae(secchi, predicted_fd_bm5),
mape = mape(secchi, predicted_fd_bm5),
bias = bias(secchi, predicted_fd_bm5),
p.bias = percent_bias(secchi, predicted_fd_bm5),
smape = smape(secchi, predicted_fd_bm5))
ggplot(preds_fd_bm5_play, aes(x = secchi, y = predicted_fd_bm5)) +
geom_point() +
geom_abline(color = 'grey', lty = 2) +
coord_cartesian(xlim = c(0, 6.5),
ylim = c(0,6.5)) +
stat_poly_eq(aes(label = paste(after_stat(adj.rr.label))),
formula = y~x,
parse = TRUE,
label.y = Inf,
vjust = 1.3) +
labs(title = 'Quick xgboost - Yojoa Secchi\nfive day matchups, band and 5-day met summaries',
subtitle = 'Grey dashed line is 1:1',
x = 'Actual Secchi (m)',
y = 'Predicted Secchi (m)')  +
theme_bw()+
theme(plot.title = element_text(hjust = 0.5, face = 'bold'),
plot.subtitle = element_text(hjust = 0.5))
#set the parameters of the boost algo
params <- list(booster = "gbtree",
objective = "reg:squarederror",
eta=0.5,
gamma=1,
max_depth=6,
min_child_weight=2,
subsample=1,
colsample_bytree=1)
#run the boost algo with those settings
xgb_naive_fd_bm5_play <- xgb.train(params = params,
data = dtrain_fd_bm5,
nrounds = 1000,
watchlist = list(train = dtrain_fd_bm5,
val = dtest_fd_bm5),
print_every_n = 25,
early_stopping_rounds = 10,
maximize = F)
#set the parameters of the boost algo
params <- list(booster = "gbtree",
objective = "reg:squarederror",
eta=0.1,
gamma=1,
max_depth=6,
min_child_weight=2,
subsample=1,
colsample_bytree=1)
#run the boost algo with those settings
xgb_naive_fd_bm5_play <- xgb.train(params = params,
data = dtrain_fd_bm5,
nrounds = 1000,
watchlist = list(train = dtrain_fd_bm5,
val = dtest_fd_bm5),
print_every_n = 25,
early_stopping_rounds = 10,
maximize = F)
#set the parameters of the boost algo
params <- list(booster = "gbtree",
objective = "reg:squarederror",
eta=0.3,
gamma=1,
max_depth=6,
min_child_weight=2,
subsample=1,
colsample_bytree=1)
#run the boost algo with those settings
xgb_naive_fd_bm5_play <- xgb.train(params = params,
data = dtrain_fd_bm5,
nrounds = 1000,
watchlist = list(train = dtrain_fd_bm5,
val = dtest_fd_bm5),
print_every_n = 25,
early_stopping_rounds = 10,
maximize = F)
?xgb.train
#set the parameters of the boost algo
params <- list(booster = "gbtree",
objective = "reg:squarederror",
eta=0.3,
gamma=2,
max_depth=6,
min_child_weight=2,
subsample=1,
colsample_bytree=1)
#run the boost algo with those settings
xgb_naive_fd_bm5_play <- xgb.train(params = params,
data = dtrain_fd_bm5,
nrounds = 1000,
watchlist = list(train = dtrain_fd_bm5,
val = dtest_fd_bm5),
print_every_n = 25,
early_stopping_rounds = 10,
maximize = F)
#set the parameters of the boost algo
params <- list(booster = "gbtree",
objective = "reg:squarederror",
eta=0.3,
gamma=3,
max_depth=6,
min_child_weight=2,
subsample=1,
colsample_bytree=1)
#run the boost algo with those settings
xgb_naive_fd_bm5_play <- xgb.train(params = params,
data = dtrain_fd_bm5,
nrounds = 1000,
watchlist = list(train = dtrain_fd_bm5,
val = dtest_fd_bm5),
print_every_n = 25,
early_stopping_rounds = 10,
maximize = F)
#set the parameters of the boost algo
params <- list(booster = "gbtree",
objective = "reg:squarederror",
eta=0.3,
gamma=2,
max_depth=6,
min_child_weight=2,
subsample=1,
colsample_bytree=1)
#run the boost algo with those settings
xgb_naive_fd_bm5_play <- xgb.train(params = params,
data = dtrain_fd_bm5,
nrounds = 1000,
watchlist = list(train = dtrain_fd_bm5,
val = dtest_fd_bm5),
print_every_n = 25,
early_stopping_rounds = 10,
maximize = F)
#set the parameters of the boost algo
params <- list(booster = "gbtree",
objective = "reg:squarederror",
eta=0.3,
gamma=1,
max_depth=6,
min_child_weight=2,
subsample=1,
colsample_bytree=1)
#run the boost algo with those settings
xgb_naive_fd_bm5_play <- xgb.train(params = params,
data = dtrain_fd_bm5,
nrounds = 1000,
watchlist = list(train = dtrain_fd_bm5,
val = dtest_fd_bm5),
print_every_n = 25,
early_stopping_rounds = 10,
maximize = F)
#set the parameters of the boost algo
params <- list(booster = "gbtree",
objective = "reg:squarederror",
eta=0.3,
gamma=0.5,
max_depth=6,
min_child_weight=2,
subsample=1,
colsample_bytree=1)
#run the boost algo with those settings
xgb_naive_fd_bm5_play <- xgb.train(params = params,
data = dtrain_fd_bm5,
nrounds = 1000,
watchlist = list(train = dtrain_fd_bm5,
val = dtest_fd_bm5),
print_every_n = 25,
early_stopping_rounds = 10,
maximize = F)
#set the parameters of the boost algo
params <- list(booster = "gbtree",
objective = "reg:squarederror",
eta=0.3,
gamma=0.75,
max_depth=6,
min_child_weight=2,
subsample=1,
colsample_bytree=1)
#run the boost algo with those settings
xgb_naive_fd_bm5_play <- xgb.train(params = params,
data = dtrain_fd_bm5,
nrounds = 1000,
watchlist = list(train = dtrain_fd_bm5,
val = dtest_fd_bm5),
print_every_n = 25,
early_stopping_rounds = 10,
maximize = F)
#set the parameters of the boost algo
params <- list(booster = "gbtree",
objective = "reg:squarederror",
eta=0.3,
gamma=6,
max_depth=6,
min_child_weight=2,
subsample=1,
colsample_bytree=1)
#run the boost algo with those settings
xgb_naive_fd_bm5_play <- xgb.train(params = params,
data = dtrain_fd_bm5,
nrounds = 1000,
watchlist = list(train = dtrain_fd_bm5,
val = dtest_fd_bm5),
print_every_n = 25,
early_stopping_rounds = 10,
maximize = F)
#set the parameters of the boost algo
params <- list(booster = "gbtree",
objective = "reg:squarederror",
eta=0.3,
gamma=6,
max_depth=5,
min_child_weight=2,
subsample=1,
colsample_bytree=1)
#run the boost algo with those settings
xgb_naive_fd_bm5_play <- xgb.train(params = params,
data = dtrain_fd_bm5,
nrounds = 1000,
watchlist = list(train = dtrain_fd_bm5,
val = dtest_fd_bm5),
print_every_n = 25,
early_stopping_rounds = 10,
maximize = F)
#set the parameters of the boost algo
params <- list(booster = "gbtree",
objective = "reg:squarederror",
eta=0.3,
gamma=6,
max_depth=5,
min_child_weight=3,
subsample=1,
colsample_bytree=1)
#run the boost algo with those settings
xgb_naive_fd_bm5_play <- xgb.train(params = params,
data = dtrain_fd_bm5,
nrounds = 1000,
watchlist = list(train = dtrain_fd_bm5,
val = dtest_fd_bm5),
print_every_n = 25,
early_stopping_rounds = 10,
maximize = F)
#set the parameters of the boost algo
params <- list(booster = "gbtree",
objective = "reg:squarederror",
eta=0.3,
gamma=6,
max_depth=5,
min_child_weight=1,
subsample=1,
colsample_bytree=1)
#run the boost algo with those settings
xgb_naive_fd_bm5_play <- xgb.train(params = params,
data = dtrain_fd_bm5,
nrounds = 1000,
watchlist = list(train = dtrain_fd_bm5,
val = dtest_fd_bm5),
print_every_n = 25,
early_stopping_rounds = 10,
maximize = F)
#set the parameters of the boost algo
params <- list(booster = "gbtree",
objective = "reg:squarederror",
eta=0.3,
gamma=6,
max_depth=5,
min_child_weight=2,
subsample=1,
colsample_bytree=1)
#run the boost algo with those settings
xgb_naive_fd_bm5_play <- xgb.train(params = params,
data = dtrain_fd_bm5,
nrounds = 1000,
watchlist = list(train = dtrain_fd_bm5,
val = dtest_fd_bm5),
print_every_n = 25,
early_stopping_rounds = 10,
maximize = F)
#set the parameters of the boost algo
params <- list(booster = "gbtree",
objective = "reg:squarederror",
eta=0.3,
gamma=2,
max_depth=5,
min_child_weight=2,
subsample=1,
colsample_bytree=1)
#run the boost algo with those settings
xgb_naive_fd_bm5_play <- xgb.train(params = params,
data = dtrain_fd_bm5,
nrounds = 1000,
watchlist = list(train = dtrain_fd_bm5,
val = dtest_fd_bm5),
print_every_n = 25,
early_stopping_rounds = 10,
maximize = F)
preds_fd_bm5_play <- test_fiveDay %>% mutate(predicted_fd_bm5 = predict(xgb_naive_fd_bm5_play, dtest_fd_bm5))
evals_fd_bm5_play <- preds_fd_bm5_play %>%
summarise(rmse = rmse(secchi, predicted_fd_bm5),
mae = mae(secchi, predicted_fd_bm5),
mape = mape(secchi, predicted_fd_bm5),
bias = bias(secchi, predicted_fd_bm5),
p.bias = percent_bias(secchi, predicted_fd_bm5),
smape = smape(secchi, predicted_fd_bm5))
ggplot(preds_fd_bm5_play, aes(x = secchi, y = predicted_fd_bm5)) +
geom_point() +
geom_abline(color = 'grey', lty = 2) +
coord_cartesian(xlim = c(0, 6.5),
ylim = c(0,6.5)) +
stat_poly_eq(aes(label = paste(after_stat(adj.rr.label))),
formula = y~x,
parse = TRUE,
label.y = Inf,
vjust = 1.3) +
labs(title = 'Quick xgboost - Yojoa Secchi\nfive day matchups, band and 5-day met summaries',
subtitle = 'Grey dashed line is 1:1',
x = 'Actual Secchi (m)',
y = 'Predicted Secchi (m)')  +
theme_bw()+
theme(plot.title = element_text(hjust = 0.5, face = 'bold'),
plot.subtitle = element_text(hjust = 0.5))
#set the parameters of the boost algo
params <- list(booster = "gbtree",
objective = "reg:squarederror",
eta=0.2,
gamma=2,
max_depth=5,
min_child_weight=2,
subsample=1,
colsample_bytree=1)
#run the boost algo with those settings
xgb_naive_fd_bm5_play <- xgb.train(params = params,
data = dtrain_fd_bm5,
nrounds = 1000,
watchlist = list(train = dtrain_fd_bm5,
val = dtest_fd_bm5),
print_every_n = 25,
early_stopping_rounds = 10,
maximize = F)
#set the parameters of the boost algo
params <- list(booster = "gbtree",
objective = "reg:squarederror",
eta=0.5,
gamma=2,
max_depth=5,
min_child_weight=2,
subsample=1,
colsample_bytree=1)
#run the boost algo with those settings
xgb_naive_fd_bm5_play <- xgb.train(params = params,
data = dtrain_fd_bm5,
nrounds = 1000,
watchlist = list(train = dtrain_fd_bm5,
val = dtest_fd_bm5),
print_every_n = 25,
early_stopping_rounds = 10,
maximize = F)
#set the parameters of the boost algo
params <- list(booster = "gbtree",
objective = "reg:squarederror",
eta=0.4,
gamma=2,
max_depth=5,
min_child_weight=2,
subsample=1,
colsample_bytree=1)
#run the boost algo with those settings
xgb_naive_fd_bm5_play <- xgb.train(params = params,
data = dtrain_fd_bm5,
nrounds = 1000,
watchlist = list(train = dtrain_fd_bm5,
val = dtest_fd_bm5),
print_every_n = 25,
early_stopping_rounds = 10,
maximize = F)
#set the parameters of the boost algo
params <- list(booster = "gbtree",
objective = "reg:squarederror",
eta=0.3,
gamma=2,
max_depth=5,
min_child_weight=2,
subsample=1,
colsample_bytree=1)
#run the boost algo with those settings
xgb_naive_fd_bm5_play <- xgb.train(params = params,
data = dtrain_fd_bm5,
nrounds = 1000,
watchlist = list(train = dtrain_fd_bm5,
val = dtest_fd_bm5),
print_every_n = 25,
early_stopping_rounds = 10,
maximize = F)
#set the parameters of the boost algo
params <- list(booster = "gbtree",
objective = "reg:squarederror",
eta=0.3,
gamma=3,
max_depth=5,
min_child_weight=2,
subsample=1,
colsample_bytree=1)
#run the boost algo with those settings
xgb_naive_fd_bm5_play <- xgb.train(params = params,
data = dtrain_fd_bm5,
nrounds = 1000,
watchlist = list(train = dtrain_fd_bm5,
val = dtest_fd_bm5),
print_every_n = 25,
early_stopping_rounds = 10,
maximize = F)
#set the parameters of the boost algo
params <- list(booster = "gbtree",
objective = "reg:squarederror",
eta=0.3,
gamma=2,
max_depth=5,
min_child_weight=2,
subsample=1,
colsample_bytree=1)
